{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_epocht=250\n",
    "parser.add_argument('--shot', type=int, default=1)\n",
    "parser.add_argument('--test-way', type=int, default=5)\n",
    "parser.add_argument('--test-shot', type=int, default=1)\n",
    "parser.add_argument('--test-query', type=int, default=30)\n",
    "parser.add_argument('--train-query', type=int, default=15)\n",
    "\n",
    "train_way=30\n",
    "parser.add_argument('--gpu', default=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import learn2learn as l2l\n",
    "from learn2learn.data.transforms import NWays, KShots, LoadData, RemapLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances_logits(a, b):\n",
    "    n = a.shape[0]\n",
    "    m = b.shape[0]\n",
    "    logits = -((a.unsqueeze(1).expand(n, m, -1) -\n",
    "                b.unsqueeze(0).expand(n, m, -1))**2).sum(dim=2)\n",
    "    return logits\n",
    "\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
    "    return (predictions == targets).sum().float() / targets.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convnet(nn.Module):\n",
    "\n",
    "    def __init__(self, x_dim=3, hid_dim=64, z_dim=64):\n",
    "        super().__init__()\n",
    "        self.encoder = l2l.vision.models.CNN4Backbone(\n",
    "            hidden_size=hid_dim,\n",
    "            channels=x_dim,\n",
    "            max_pool=True,\n",
    "       )\n",
    "        self.out_channels = 1600\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_adapt(model, batch, ways, shot, query_num, metric=None, device=None):\n",
    "    if metric is None:\n",
    "        metric = pairwise_distances_logits\n",
    "    if device is None:\n",
    "        device = model.device()\n",
    "    data, labels = batch\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "    n_items = shot * ways\n",
    "\n",
    "    # Sort data samples by labels\n",
    "    # TODO: Can this be replaced by ConsecutiveLabels ?\n",
    "    sort = torch.sort(labels)\n",
    "    data = data.squeeze(0)[sort.indices].squeeze(0)\n",
    "    labels = labels.squeeze(0)[sort.indices].squeeze(0)\n",
    "\n",
    "    # Compute support and query embeddings\n",
    "    embeddings = model(data)\n",
    "    support_indices = np.zeros(data.size(0), dtype=bool)\n",
    "    selection = np.arange(ways) * (shot + query_num)\n",
    "    for offset in range(shot):\n",
    "        support_indices[selection + offset] = True\n",
    "    query_indices = torch.from_numpy(~support_indices)\n",
    "    support_indices = torch.from_numpy(support_indices)\n",
    "    support = embeddings[support_indices]\n",
    "    support = support.reshape(ways, shot, -1).mean(dim=1)\n",
    "    query = embeddings[query_indices]\n",
    "    labels = labels[query_indices].long()\n",
    "\n",
    "    logits = pairwise_distances_logits(query, support)\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    acc = accuracy(logits, labels)\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if args.gpu and torch.cuda.device_count():\n",
    "    print(\"Using gpu\")\n",
    "    torch.cuda.manual_seed(43)\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "model = Convnet()\n",
    "model.to(device)\n",
    "\n",
    "path_data = '~/data'\n",
    "train_dataset = l2l.vision.datasets.MiniImagenet(\n",
    "    root=path_data, mode='train', download=True)\n",
    "valid_dataset = l2l.vision.datasets.MiniImagenet(\n",
    "    root=path_data, mode='validation', download=True)\n",
    "test_dataset = l2l.vision.datasets.MiniImagenet(\n",
    "    root=path_data, mode='test', download=True)\n",
    "\n",
    "train_dataset = l2l.data.MetaDataset(train_dataset)\n",
    "train_transforms = [\n",
    "    NWays(train_dataset, args.train_way),\n",
    "    KShots(train_dataset, args.train_query + args.shot),\n",
    "    LoadData(train_dataset),\n",
    "    RemapLabels(train_dataset),\n",
    "]\n",
    "train_tasks = l2l.data.Taskset(train_dataset, task_transforms=train_transforms)\n",
    "train_loader = DataLoader(train_tasks, pin_memory=True, shuffle=True)\n",
    "\n",
    "valid_dataset = l2l.data.MetaDataset(valid_dataset)\n",
    "valid_transforms = [\n",
    "    NWays(valid_dataset, args.test_way),\n",
    "    KShots(valid_dataset, args.test_query + args.test_shot),\n",
    "    LoadData(valid_dataset),\n",
    "    RemapLabels(valid_dataset),\n",
    "]\n",
    "valid_tasks = l2l.data.Taskset(\n",
    "    valid_dataset,\n",
    "    task_transforms=valid_transforms,\n",
    "    num_tasks=200,\n",
    ")\n",
    "valid_loader = DataLoader(valid_tasks, pin_memory=True, shuffle=True)\n",
    "\n",
    "test_dataset = l2l.data.MetaDataset(test_dataset)\n",
    "test_transforms = [\n",
    "    NWays(test_dataset, args.test_way),\n",
    "    KShots(test_dataset, args.test_query + args.test_shot),\n",
    "    LoadData(test_dataset),\n",
    "    RemapLabels(test_dataset),\n",
    "]\n",
    "test_tasks = l2l.data.Taskset(\n",
    "    test_dataset,\n",
    "    task_transforms=test_transforms,\n",
    "    num_tasks=2000,\n",
    ")\n",
    "test_loader = DataLoader(test_tasks, pin_memory=True, shuffle=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "for epoch in range(1, args.max_epoch + 1):\n",
    "    model.train()\n",
    "\n",
    "    loss_ctr = 0\n",
    "    n_loss = 0\n",
    "    n_acc = 0\n",
    "\n",
    "    for i in range(100):\n",
    "        batch = next(iter(train_loader))\n",
    "\n",
    "        loss, acc = fast_adapt(model,\n",
    "                                batch,\n",
    "                                args.train_way,\n",
    "                                args.shot,\n",
    "                                args.train_query,\n",
    "                                metric=pairwise_distances_logits,\n",
    "                                device=device)\n",
    "\n",
    "        loss_ctr += 1\n",
    "        n_loss += loss.item()\n",
    "        n_acc += acc\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    print('epoch {}, train, loss={:.4f} acc={:.4f}'.format(\n",
    "        epoch, n_loss/loss_ctr, n_acc/loss_ctr))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss_ctr = 0\n",
    "    n_loss = 0\n",
    "    n_acc = 0\n",
    "    for i, batch in enumerate(valid_loader):\n",
    "        loss, acc = fast_adapt(model,\n",
    "                                batch,\n",
    "                                args.test_way,\n",
    "                                args.test_shot,\n",
    "                                args.test_query,\n",
    "                                metric=pairwise_distances_logits,\n",
    "                                device=device)\n",
    "\n",
    "        loss_ctr += 1\n",
    "        n_loss += loss.item()\n",
    "        n_acc += acc\n",
    "\n",
    "    print('epoch {}, val, loss={:.4f} acc={:.4f}'.format(\n",
    "        epoch, n_loss/loss_ctr, n_acc/loss_ctr))\n",
    "\n",
    "loss_ctr = 0\n",
    "n_acc = 0\n",
    "\n",
    "for i, batch in enumerate(test_loader, 1):\n",
    "    loss, acc = fast_adapt(model,\n",
    "                            batch,\n",
    "                            args.test_way,\n",
    "                            args.test_shot,\n",
    "                            args.test_query,\n",
    "                            metric=pairwise_distances_logits,\n",
    "                            device=device)\n",
    "    loss_ctr += 1\n",
    "    n_acc += acc\n",
    "    print('batch {}: {:.2f}({:.2f})'.format(\n",
    "        i, n_acc/loss_ctr * 100, acc * 100))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

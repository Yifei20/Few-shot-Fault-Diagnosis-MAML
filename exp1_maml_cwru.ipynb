{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-way, K-shot few-Shot learning parameters\n",
    "ways=10             # Number of classes in a task\n",
    "shots=5             # Number of training examples per class (same for testing)\n",
    "# Meta-learning parameters\n",
    "meta_lr=0.001       # Outer loop learning rate\n",
    "fast_lr=0.1         # Inner loop learning rate\n",
    "adapt_steps=5       # Number of inner loop update steps\n",
    "meta_batch_size=32  # Number of tasks sampled per batch\n",
    "iterations=5        # Number of outer loop iterations\n",
    "# Cuda and random seed settings\n",
    "cuda=True\n",
    "seed=42\n",
    "# Dataset parameters (different domain means different working condition)\n",
    "train_domain=1      # For CWRU dataset: 0: 1797, 1: 1772, 2: 1750, 3: 1730\n",
    "valid_domain=2     \n",
    "test_domain=3\n",
    "# Path to the data directory\n",
    "data_dir_path='./data'\n",
    "\n",
    "test_step = 50\n",
    "display_step = 1\n",
    "expriment_name = 'MAML_CWRU_10w_5s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.cwru import CWRU\n",
    "from utils import (setlogger, fast_adapt)\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "import learn2learn as l2l\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from learn2learn.data.transforms import (\n",
    "    FusedNWaysKShots,\n",
    "    LoadData,\n",
    "    RemapLabels,\n",
    "    ConsecutiveLabels,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Checking and Random Seed Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Random Seed\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Set training device, using GPU if available\n",
    "if cuda and torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    device_count = torch.cuda.device_count()\n",
    "    device = torch.device('cuda')\n",
    "    logging.info('Training MAML with {} GPU(s).'.format(device_count))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    logging.info('Training MAML with CPU.')\n",
    "\n",
    "# set the logger\n",
    "if not os.path.exists(\"./logs\"):\n",
    "    os.makedirs(\"./logs\")\n",
    "setlogger(os.path.join(\"./logs\", expriment_name + '.log'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Meta-data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Datasets\n",
    "train_dataset = CWRU(train_domain,\n",
    "                        data_dir_path)\n",
    "\n",
    "valid_dataset = CWRU(valid_domain,\n",
    "                        data_dir_path)\n",
    "\n",
    "test_dataset = CWRU(test_domain,\n",
    "                    data_dir_path)\n",
    "\n",
    "# Create Meta-Datasets\n",
    "train_dataset = l2l.data.MetaDataset(train_dataset)\n",
    "valid_dataset = l2l.data.MetaDataset(valid_dataset)\n",
    "test_dataset = l2l.data.MetaDataset(test_dataset)\n",
    "\n",
    "# Create Meta-Tasks\n",
    "train_transforms = [\n",
    "    FusedNWaysKShots(train_dataset, n=ways, k=2*shots),\n",
    "    LoadData(train_dataset),\n",
    "    RemapLabels(train_dataset),\n",
    "    ConsecutiveLabels(train_dataset),\n",
    "]\n",
    "train_tasks = l2l.data.Taskset(\n",
    "    train_dataset,\n",
    "    task_transforms=train_transforms,\n",
    "    num_tasks=400,\n",
    ")\n",
    "\n",
    "valid_transforms = [\n",
    "    FusedNWaysKShots(valid_dataset, n=ways, k=2*shots),\n",
    "    LoadData(valid_dataset),\n",
    "    ConsecutiveLabels(valid_dataset),\n",
    "    RemapLabels(valid_dataset),\n",
    "]\n",
    "valid_tasks = l2l.data.Taskset(\n",
    "    valid_dataset,\n",
    "    task_transforms=valid_transforms,\n",
    "    num_tasks=100,\n",
    ")\n",
    "\n",
    "test_transforms = [\n",
    "    FusedNWaysKShots(test_dataset, n=ways, k=2*shots),\n",
    "    LoadData(test_dataset),\n",
    "    RemapLabels(test_dataset),\n",
    "    ConsecutiveLabels(test_dataset),\n",
    "]\n",
    "test_tasks = l2l.data.Taskset(\n",
    "    test_dataset,\n",
    "    task_transforms=test_transforms,\n",
    "    num_tasks=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "model = l2l.vision.models.CNN4(output_size=10)\n",
    "model.to(device)\n",
    "maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n",
    "opt = torch.optim.Adam(model.parameters(), meta_lr)\n",
    "loss = nn.CrossEntropyLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking Acc and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_list = []\n",
    "valid_acc_list = []\n",
    "train_err_list = []\n",
    "valid_err_list = []\n",
    "\n",
    "test_acc_list = []\n",
    "test_err_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7d/zny8jmrj715bf909l1np7dfr0000gn/T/ipykernel_63541/1256290378.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                                             \u001b[0mways\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                                             device)\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mevaluation_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mmeta_train_error\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mevaluation_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmeta_train_accuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mevaluation_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iteration in range(1, iterations+1):\n",
    "    opt.zero_grad()\n",
    "    meta_train_err_sum = 0.0\n",
    "    meta_train_acc_sum = 0.0\n",
    "    meta_valid_err_sum = 0.0\n",
    "    meta_valid_acc_sum = 0.0\n",
    "\n",
    "    for task in range(meta_batch_size):\n",
    "        # Compute meta-training loss\n",
    "        learner = maml.clone()\n",
    "        batch = train_tasks.sample()\n",
    "        evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
    "                                                            learner,\n",
    "                                                            loss,\n",
    "                                                            adapt_steps,\n",
    "                                                            shots,\n",
    "                                                            ways,\n",
    "                                                            device)\n",
    "        evaluation_error.backward()\n",
    "        meta_train_err_sum += evaluation_error.item()\n",
    "        meta_train_acc_sum += evaluation_accuracy.item()\n",
    "        \n",
    "        # Compute meta-validation loss\n",
    "        learner = maml.clone()\n",
    "        batch = valid_tasks.sample()\n",
    "        evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
    "                                                            learner,\n",
    "                                                            loss,\n",
    "                                                            adapt_steps,\n",
    "                                                            shots,\n",
    "                                                            ways,\n",
    "                                                            device)\n",
    "        meta_valid_err_sum += evaluation_error.item()\n",
    "        meta_valid_acc_sum += evaluation_accuracy.item()\n",
    "\n",
    "    # Train\n",
    "    meta_train_acc = meta_train_acc_sum / meta_batch_size\n",
    "    meta_train_err = meta_train_err_sum / meta_batch_size\n",
    "    train_acc_list.append(meta_train_acc)\n",
    "    train_err_list.append(meta_train_err)\n",
    "    # Valid\n",
    "    meta_valid_acc = meta_valid_acc_sum / meta_batch_size\n",
    "    meta_valid_err = meta_valid_err_sum / meta_batch_size\n",
    "    valid_acc_list.append(meta_valid_acc)\n",
    "    valid_err_list.append(meta_valid_err)\n",
    "\n",
    "    # Print some metrics\n",
    "    # print('\\n')\n",
    "    logging.info('Iteration {}:'.format(iteration))\n",
    "    logging.info('Meta Train Error: {}.'.format(meta_train_err))\n",
    "    logging.info('Meta Train Accuracy: {}.'.format(meta_train_acc))\n",
    "    logging.info('Meta Valid Error: {}.'.format(meta_valid_err))\n",
    "    logging.info('Meta Valid Accuracy: {}.\\n'.format(meta_valid_acc))\n",
    "\n",
    "    # Compute meta-testing loss\n",
    "    if (iteration % test_step == 0):\n",
    "        meta_test_error = 0.0\n",
    "        meta_test_accuracy = 0.0\n",
    "        for task in range(meta_batch_size):\n",
    "            learner = maml.clone()\n",
    "            batch = test_tasks.sample()\n",
    "            evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
    "                                                                learner,\n",
    "                                                                loss,\n",
    "                                                                adapt_steps,\n",
    "                                                                shots,\n",
    "                                                                ways,\n",
    "                                                                device)\n",
    "            meta_test_error += evaluation_error.item()\n",
    "            meta_test_accuracy += evaluation_accuracy.item()\n",
    "        # print('\\n')\n",
    "        logging.info('Meta Test Error: {}.'.format(meta_test_error / meta_batch_size))\n",
    "        logging.info('Meta Test Accuracy: {}.\\n'.format(meta_test_accuracy / meta_batch_size))\n",
    "\n",
    "    # ========================= plot ==========================\n",
    "    if (iteration % display_step == 0):\n",
    "        x_ticks = np.arange(1, iterations, 1)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(121)\n",
    "        plt.plot(train_acc_list, '-o', label=\"train acc\")\n",
    "        plt.plot(valid_acc_list, '-o', label=\"valid acc\")\n",
    "        plt.xticks(x_ticks)\n",
    "        plt.xlabel('Trainin iteration')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title(\"Accuracy Curve by Iteration\")\n",
    "        plt.legend()\n",
    "        plt.subplot(122)\n",
    "        plt.plot(train_err_list, '-o', label=\"train loss\")\n",
    "        plt.plot(valid_err_list, '-o', label=\"valid loss\")\n",
    "        plt.xticks(x_ticks)\n",
    "        plt.xlabel('Trainin iteration')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title(\"Loss Curve by Iteration\")\n",
    "        plt.legend()\n",
    "        plt.suptitle(\"CWRU Bearing Fault Diagnosis {}way-{}shot\".format(ways, shots))\n",
    "        plt.savefig('./results/' + expriment_name + '_{}.png'.format(iteration))\n",
    "        plt.show()\n",
    "\n",
    "    # Average the accumulated gradients and optimize\n",
    "    for p in model.parameters():\n",
    "        p.grad.data.mul_(1.0 / meta_batch_size)\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

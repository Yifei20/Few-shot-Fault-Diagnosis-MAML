{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MAML_CWRU_10w_5s'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment settings\n",
    "model_name = 'MAML'\n",
    "dataset_name = 'CWRU'\n",
    "ways=10             # Number of classes in a task\n",
    "shots=5             # Number of training examples per class (same for testing)\n",
    "expriment_name = '{}_{}_{}w_{}s'.format(model_name, dataset_name, ways, shots)\n",
    "# Meta-learning parameters\n",
    "meta_lr=0.001       # Outer loop learning rate\n",
    "fast_lr=0.1         # Inner loop learning rate\n",
    "adapt_steps=5       # Number of inner loop update steps\n",
    "meta_batch_size=32  # Number of tasks sampled per batch\n",
    "iterations=1001      # Number of outer loop iterations\n",
    "# Cuda and random seed settings\n",
    "cuda=True\n",
    "seed=42\n",
    "# Dataset parameters (different domain means different working condition)\n",
    "train_domain=1      # For CWRU dataset: 0: 1797, 1: 1772, 2: 1750, 3: 1730\n",
    "valid_domain=2     \n",
    "test_domain=3\n",
    "# Path to the data directory\n",
    "data_dir_path='./data'\n",
    "\n",
    "# test_step = 50\n",
    "test_batch_size = 32\n",
    "display_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.cwru import CWRU\n",
    "from utils import fast_adapt\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import learn2learn as l2l\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from learn2learn.data.transforms import (\n",
    "    FusedNWaysKShots,\n",
    "    LoadData,\n",
    "    RemapLabels,\n",
    "    ConsecutiveLabels,\n",
    ")\n",
    "# Set the logger\n",
    "\n",
    "# setlogger(os.path.join(\"./logs\", expriment_name + '.log'))\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "fh = logging.FileHandler(os.path.join(\"./logs\", expriment_name + '.log'))\n",
    "fh.setLevel(logging.INFO)\n",
    "# ch = logging.StreamHandler()\n",
    "# ch.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter(\"[%(asctime)s] %(message)s\",\n",
    "                                   datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "fh.setFormatter(formatter)\n",
    "# ch.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "# logger.addHandler(ch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Checking and Random Seed Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Random Seed\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Set training device, using GPU if available\n",
    "if cuda and torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    device_count = torch.cuda.device_count()\n",
    "    device = torch.device('cuda')\n",
    "    logging.info('Training MAML with {} GPU(s).'.format(device_count))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    logging.info('Training MAML with CPU.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Meta-data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Datasets\n",
    "train_dataset = CWRU(train_domain,\n",
    "                        data_dir_path)\n",
    "\n",
    "valid_dataset = CWRU(valid_domain,\n",
    "                        data_dir_path)\n",
    "\n",
    "test_dataset = CWRU(test_domain,\n",
    "                    data_dir_path)\n",
    "\n",
    "# Create Meta-Datasets\n",
    "train_dataset = l2l.data.MetaDataset(train_dataset)\n",
    "valid_dataset = l2l.data.MetaDataset(valid_dataset)\n",
    "test_dataset = l2l.data.MetaDataset(test_dataset)\n",
    "\n",
    "# Create Meta-Tasks\n",
    "train_transforms = [\n",
    "    FusedNWaysKShots(train_dataset, n=ways, k=2*shots),\n",
    "    LoadData(train_dataset),\n",
    "    RemapLabels(train_dataset),\n",
    "    ConsecutiveLabels(train_dataset),\n",
    "]\n",
    "train_tasks = l2l.data.Taskset(\n",
    "    train_dataset,\n",
    "    task_transforms=train_transforms,\n",
    "    num_tasks=400,\n",
    ")\n",
    "\n",
    "valid_transforms = [\n",
    "    FusedNWaysKShots(valid_dataset, n=ways, k=2*shots),\n",
    "    LoadData(valid_dataset),\n",
    "    ConsecutiveLabels(valid_dataset),\n",
    "    RemapLabels(valid_dataset),\n",
    "]\n",
    "valid_tasks = l2l.data.Taskset(\n",
    "    valid_dataset,\n",
    "    task_transforms=valid_transforms,\n",
    "    num_tasks=100,\n",
    ")\n",
    "\n",
    "test_transforms = [\n",
    "    FusedNWaysKShots(test_dataset, n=ways, k=2*shots),\n",
    "    LoadData(test_dataset),\n",
    "    RemapLabels(test_dataset),\n",
    "    ConsecutiveLabels(test_dataset),\n",
    "]\n",
    "test_tasks = l2l.data.Taskset(\n",
    "    test_dataset,\n",
    "    task_transforms=test_transforms,\n",
    "    num_tasks=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "model = l2l.vision.models.CNN4(output_size=10)\n",
    "model.to(device)\n",
    "maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n",
    "opt = torch.optim.Adam(model.parameters(), meta_lr)\n",
    "loss = nn.CrossEntropyLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking Acc and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_list = []\n",
    "valid_acc_list = []\n",
    "train_err_list = []\n",
    "valid_err_list = []\n",
    "\n",
    "test_acc_list = []\n",
    "test_err_list = []\n",
    "\n",
    "best_valid_err = float('inf')\n",
    "best_train_err = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(iterations):\n",
    "    opt.zero_grad()\n",
    "    meta_train_err_sum = 0.0\n",
    "    meta_train_acc_sum = 0.0\n",
    "    meta_valid_err_sum = 0.0\n",
    "    meta_valid_acc_sum = 0.0\n",
    "\n",
    "    for task in range(meta_batch_size):\n",
    "        # Compute meta-training loss\n",
    "        learner = maml.clone()\n",
    "        batch = train_tasks.sample()\n",
    "        evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
    "                                                            learner,\n",
    "                                                            loss,\n",
    "                                                            adapt_steps,\n",
    "                                                            shots,\n",
    "                                                            ways,\n",
    "                                                            device)\n",
    "        evaluation_error.backward()\n",
    "        meta_train_err_sum += evaluation_error.item()\n",
    "        meta_train_acc_sum += evaluation_accuracy.item()\n",
    "        \n",
    "        # Compute meta-validation loss\n",
    "        learner = maml.clone()\n",
    "        batch = valid_tasks.sample()\n",
    "        evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
    "                                                            learner,\n",
    "                                                            loss,\n",
    "                                                            adapt_steps,\n",
    "                                                            shots,\n",
    "                                                            ways,\n",
    "                                                            device)\n",
    "        meta_valid_err_sum += evaluation_error.item()\n",
    "        meta_valid_acc_sum += evaluation_accuracy.item()\n",
    "\n",
    "    # Train\n",
    "    meta_train_acc = meta_train_acc_sum / meta_batch_size\n",
    "    meta_train_err = meta_train_err_sum / meta_batch_size\n",
    "    # Valid\n",
    "    meta_valid_acc = meta_valid_acc_sum / meta_batch_size\n",
    "    meta_valid_err = meta_valid_err_sum / meta_batch_size\n",
    "\n",
    "    if meta_valid_err <= best_valid_err and meta_train_err <= best_train_err:\n",
    "        logging.info('Saving best model...')\n",
    "        logging.info('Train error improved from {} to {}'.format(best_train_err, meta_train_err))\n",
    "        logging.info('Valid error improved from {} to {}'.format(best_valid_err, meta_valid_err))\n",
    "        best_valid_err = meta_valid_err\n",
    "        best_train_err = meta_train_err\n",
    "        if not os.path.exists(\"./models\"):\n",
    "            os.makedirs(\"./models\")\n",
    "        torch.save(model.state_dict(), './models/' + expriment_name + '_best.pth')\n",
    "\n",
    "    train_acc_list.append(meta_train_acc)\n",
    "    train_err_list.append(meta_train_err)\n",
    "    valid_acc_list.append(meta_valid_acc)\n",
    "    valid_err_list.append(meta_valid_err)\n",
    "\n",
    "    # Print some metrics\n",
    "    logging.info('Iteration {}:'.format(iteration))\n",
    "    logging.info('Meta Train Error: {}.'.format(meta_train_err))\n",
    "    logging.info('Meta Train Accuracy: {}.'.format(meta_train_acc))\n",
    "    logging.info('Meta Valid Error: {}.'.format(meta_valid_err))\n",
    "    logging.info('Meta Valid Accuracy: {}.'.format(meta_valid_acc))\n",
    "\n",
    "    # ========================= plot ==========================\n",
    "    if (iteration % display_step == 0 and iteration != 0):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(121)\n",
    "        plt.plot(train_acc_list, '-o', label=\"train acc\")\n",
    "        plt.plot(valid_acc_list, '-o', label=\"valid acc\")\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title(\"Accuracy Curve by Iteration\")\n",
    "        plt.legend()\n",
    "        plt.subplot(122)\n",
    "        plt.plot(train_err_list, '-o', label=\"train loss\")\n",
    "        plt.plot(valid_err_list, '-o', label=\"valid loss\")\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title(\"Loss Curve by Iteration\")\n",
    "        plt.legend()\n",
    "        plt.suptitle(\"CWRU Bearing Fault Diagnosis {}way-{}shot\".format(ways, shots))\n",
    "        plt.savefig('./results/' + expriment_name + '_{}.png'.format(iteration))\n",
    "        plt.show()\n",
    "\n",
    "    # Compute meta-testing loss and accuracy if iteration >= 150\n",
    "    if iteration >= 150:\n",
    "        meta_test_error = 0.0\n",
    "        meta_test_accuracy = 0.0\n",
    "        model.load_state_dict(torch.load('./models/' + expriment_name + '_best.pth'))\n",
    "        for task in range(test_batch_size):\n",
    "            learner = maml.clone()\n",
    "            batch = test_tasks.sample()\n",
    "            evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
    "                                                                learner,\n",
    "                                                                loss,\n",
    "                                                                adapt_steps,\n",
    "                                                                shots,\n",
    "                                                                ways,\n",
    "                                                                device)\n",
    "            meta_test_error += evaluation_error.item()\n",
    "            meta_test_accuracy += evaluation_accuracy.item()\n",
    "        logging.info('Meta Test Results:')\n",
    "        logging.info('Meta Test Error: {}.'.format(meta_test_error / test_batch_size))\n",
    "        logging.info('Meta Test Accuracy: {}.\\n'.format(meta_test_accuracy / test_batch_size))\n",
    "\n",
    "    # Average the accumulated gradients and optimize\n",
    "    for p in model.parameters():\n",
    "        p.grad.data.mul_(1.0 / meta_batch_size)\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
